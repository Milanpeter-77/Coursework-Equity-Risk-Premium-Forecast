{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb44ccd8",
   "metadata": {},
   "source": [
    "# **Time Series Assignment**\n",
    "\n",
    "> Subject: Quantitative Investing\n",
    "\n",
    "> Authors: Hamza Ghoussy, Andreas Koulopoulos, Milan Peter and Shubham Vijay Nanewar\n",
    "\n",
    "Can we forecast the equity risk premium? In this group assignment we will analyze whether different candidate predictor variables can forecast the equity risk premium. We address this question in three parts: first, we analyze whether the predictor variables can be used to forecast the equity risk premium in-sample. Second, we analyze their predictive performance out-of-sample. Finally, we evaluate whether combining the variables improves the out-of-sample forecasting performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a4665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec3241",
   "metadata": {},
   "source": [
    "## **General Setup**\n",
    "\n",
    "The dataset *predictor_data.csv* contains the (quarterly) Welch and Goyal (2008) predictor variables. In this assignment, we use $N = 14$ out of the $15$ variables considered by Welch and Goyal (2008) and Rapach et al. (2010) as predictor variables:\n",
    "\n",
    "1. Log dividend-price ratio, D/P (`logDP`): Difference between the log of a 12-month moving sum of dividends paid on the S&P 500 index and the log of stock prices (S&P 500 index).\n",
    "2. Log dividend yield, D/Y (`logDY`): Difference between the log of a 12-month moving sum of dividends and the log of lagged stock prices.\n",
    "3. Log earnings-price ratio, E/P (`logEP`): Difference between the log of a 12-month moving sum of earnings on the S&P 500 and the log of stock prices.\n",
    "4. Log dividend-payout ratio, D/E (`logDE`): Difference between the 12-month moving sums of dividends and earnings.\n",
    "5. Stock Variance, SVAR (`svar`): Monthly sum of squared daily returns on the S&P 500.\n",
    "6. Book-to-market ratio, B/M (`b/m`): Ratio of the book value to the market value of the Dow Jones Industrial Average.\n",
    "7. Net equity expansion, NTIS (`ntis`): Ratio of a 12-month moving sum of net equity issues by NYSE-listed stocks to the total end-of-year market capitalization of NYSE stocks.\n",
    "8. Treasury bill rate, TBL (`tbl`): Interest rate on a three-month treasury bill on the secondary market.\n",
    "9. Long-term yield, LTY (`lty`): Long-term yield of government bonds.\n",
    "10. Long-term returns, LTR (`ltr`): Return on long-term government bonds.\n",
    "11. Term spread, TMS (`tms`): Difference between the long-term yield and the Treasury bill rate.\n",
    "12. Default yield spread, DFY (`dfy`): Difference between BAA- and AAA-rated corporate bond yields.\n",
    "13. Default return spread, DFR (`dfr`): Difference between long-term corporate bond and long-term government bond returns.\n",
    "14. Inflation, INFL (`lagINFL`): Inflation is calculated from the CPI (all urban consumers). Following Welch and Goyal (2008) and Rapach et al. (2010) we use $x_{i,t−1}$ for inflation since the data are released in the following month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af28a2f",
   "metadata": {},
   "source": [
    "The empirical framework is based on Welch and Goyal (2008), Rapach et al. (2010), and Rapach et al. (2016) and relies on the predictive regression model for the equity premium given by\n",
    "\n",
    "$$\n",
    "r_{t+1} = α_i + β_i x_{i,t} + ε_{t+1} \\tag{1}\n",
    "$$\n",
    "\n",
    "where $r_{t+1}$ is the return of the stock market index in excess of the risk-free interest rate, $x_{i,t}$ is the predictive variable of interest, and $ε_{t+1}$ denotes the disturbance term. Furthermore, $i$ indexes the forecast variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23c6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dfDATA = pd.read_csv(\"predictor_data.csv\")\n",
    "\n",
    "# List of predictor variables\n",
    "lPREDICTORS = ['logDP', 'logDY', 'logEP', 'logDE', 'svar', 'b/m', 'ntis', 'tbl', 'lty', 'ltr', 'tms', 'dfy', 'dfr', 'lagINFL']\n",
    "\n",
    "# Adjust sign for predictors where a negative relationship with returns is expected\n",
    "lNEGATIVE = ['ntis', 'tbl', 'lty', 'lagINFL']\n",
    "\n",
    "for p in lPREDICTORS:\n",
    "    if p in lNEGATIVE:\n",
    "            dfDATA[[p]] = -dfDATA[[p]]\n",
    "\n",
    "# Create lead return variable\n",
    "dfDATA[\"r_lead\"] = dfDATA[\"r\"].shift(-1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "dfDATA = dfDATA.dropna(subset=[\"r_lead\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d54cd2",
   "metadata": {},
   "source": [
    "## **Section 1**\n",
    "\n",
    "We perform an in-sample estimation of the predictive regression in equation $(1)$ for each $i = 1, . . . , N$. In our estimation, we take the negative of the predictor variables `ntis`, `tbl`, `lty`, and `lagINFL`, as specified in the question. We, then test the null hypothesis $H_0 : β_i = 0$ against the one-sided alternative $H_A : β_i > 0$. We made sure to report the estimated coefficients, heteroscadesticity and autocorrelation consistent $t$-statistics and the corresponding $p$-values. We also report the adjusted $R^2$ of our regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbaf0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predictor     alpha      beta    t-stat   p-value   adj. R2\n",
      "0      logDP  0.073147  0.016918  1.156706  0.124058   0.00339\n",
      "1      logDY  0.066959  0.015166  1.176557  0.120053  0.002087\n",
      "2      logEP  0.078286  0.022743  1.553994  0.060507  0.005995\n",
      "3      logDE  0.014036  -0.00232 -0.093785  0.537335 -0.002563\n",
      "4       svar  0.014355  0.135355   0.24206  0.404432 -0.002248\n",
      "5        b/m  -0.01151  0.048654  1.681117  0.046779  0.013268\n",
      "6       ntis  0.023962  0.525127  1.877998  0.030572  0.013928\n",
      "7        tbl  0.023189  0.232338   1.49274  0.068165  0.002054\n",
      "8        lty  0.025689  0.204795  1.250833  0.105881  0.000432\n",
      "9        ltr  0.013164  0.172413  1.639831  0.050932  0.003737\n",
      "10       tms   0.00984  0.342349  0.904624  0.183117 -0.000831\n",
      "11       dfy  0.009008  0.581775  0.345433  0.364979 -0.001145\n",
      "12       dfr  0.015613 -0.062966 -0.204154  0.580829 -0.002417\n",
      "13   lagINFL  0.019012  0.466832  0.681585  0.247957  0.000738\n"
     ]
    }
   ],
   "source": [
    "# model each predictor variable\n",
    "# save in a dataframe\n",
    "\n",
    "results = pd.DataFrame(columns=['Predictor', 'alpha', 'beta', 't-stat', 'p-value', 'adj. R2'])\n",
    "\n",
    "for p in lPREDICTORS:\n",
    "\n",
    "    y = dfDATA['r_lead']\n",
    "    X = sm.add_constant(dfDATA[[p]])\n",
    "\n",
    "    # create the regression model\n",
    "    # with HAC (Heteroskedasticity and Autocorrelation Consistent)\n",
    "    model = sm.OLS(y, X).fit(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "\n",
    "    t_stat = model.tvalues[p]\n",
    "    df_resid = int(model.df_resid)\n",
    "\n",
    "    # one-sided p-value (H1: beta > 0)\n",
    "    p_one = 1 - stats.t.cdf(t_stat, df_resid)\n",
    "\n",
    "    # save results in dataframe\n",
    "    results.loc[p, 'Predictor'] = p\n",
    "    results.loc[p, 'alpha'] = model.params['const']\n",
    "    results.loc[p, 'beta'] = model.params[p]\n",
    "    results.loc[p, 't-stat'] = t_stat\n",
    "    results.loc[p, 'p-value'] = p_one\n",
    "    results.loc[p, 'adj. R2'] = model.rsquared_adj\n",
    "\n",
    "# display results\n",
    "print(results.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785d025",
   "metadata": {},
   "source": [
    "## **Section 2**\n",
    "\n",
    "We perform an out-of-sample estimation of our model, using an expanding window. For this part, we divide the total sample of $T$ observations into an in-sample period consisting of the first $m$ observations, a holdout out-of-sample period consisting of $p$ observations, and an out-of-sample period composed of the last $q$ observations. In general, the equity premium forecast\n",
    "based on equation $(1)$ is given by\n",
    "\n",
    "$$\n",
    "r_{i,t+1} = \\hat{α}_{i,t} + \\hat{β}_{i,t}x_{i,t} \\tag{2}\n",
    "$$\n",
    "\n",
    "with $\\hat{α}_{i,t}$ and $\\hat{β}_{i,t}$ denoting the OLS estimates of $α_i$ and $β_i$, respectively, based on data up to and including period $t$. Thus, using the OLS estimates $\\hat{α}_{i,m+p}$ and $\\hat{β}_{i,m+p}$ of $α_i$ and $β_i$, respectively, the first out-of-sample forecast is given by\n",
    "\n",
    "$$\n",
    "\\hat{r}_{i,m+p+1} = \\hat{α}_{i,m+p} + \\hat{β}_{i,m+p}x_{i,m+p} \\tag{3}\n",
    "$$\n",
    "\n",
    "In particular, $\\{r_{t}\\}_{t=2}^{m+p}$ is regressed on a constant, and $\\{x_{i,t}\\}_{t=1}^{m+p-1}$ following equation $(1)$. The second out-of-sample forecast is generated similarly, by regressing $\\{r_{t}\\}_{t=2}^{m+p+1}$ on a constant and $\\{x_{i,t}\\}_{t=1}^{m+p}$ which yields\n",
    "\n",
    "$$\n",
    "\\hat{r}_{i,m+p+2} = \\hat{α}_{i,m+p+1} + \\hat{β}_{i,m+p+1}x_{i,m+p+1} \\tag{4}\n",
    "$$\n",
    "\n",
    "Following this procedure, we obtain $q$ out-of-sample forecasts $\\{\\hat{r}_{t}\\}_{t=m+p+1}^{T}$. We set $m$ to 20 years and $p$ to 10 years in our implementation, as specified in the introduction. In our forecast evaluation, we compare these forecasts with the historical average of the excess returns over the risk-free rate, which serves as a benchmark. In particular, the benchmark return in period $t + 1$ is given by\n",
    "\n",
    "$$\n",
    "\\bar{r}_{t+1} = \\frac{1}{t} \\sum_{j=1}^{t} r_{j} \\tag{5}\n",
    "$$\n",
    "\n",
    "To evaluate the out-of-sample performance of the different forecasts, we use the out-of-sample $R^2$, $R^2_{OS}$ (Campbell and Thompson, 2008). The out-of-sample $R^2$ compares the forecast based on the predictive regression model in equation $(1)$ $\\hat{r}_{t+1}$, with the benchmark $\\bar{r}_{t+1}$. In particular, it measures the proportional reduction in MSPE for $\\hat{r}_{t+1}$ relative to $\\bar{r}_{t+1}$:\n",
    "\n",
    "$$\n",
    "R^2_{OS} = 1 −\n",
    "\\frac{\\sum_{k=p+1}^{p+q} (r_{m+k} − \\hat{r}_{m+k})^2}{\\sum_{k=p+1}^{p+q} (r_{m+k} − \\bar{r}_{m+k})^2} \\tag{6}\n",
    "$$\n",
    "\n",
    "where $q$ are the out-of-sample observations (see above). A positive out-of-sample $R^2$ indicates that the forecast $\\hat{r}_{t+1}$ outperforms the historical average forecast in terms of MSPE. We report the out-of-sample $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39917dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample R^2_OS by predictor (expanding window):\n",
      "lagINFL    0.005288\n",
      "ltr        0.004127\n",
      "dfy        0.001243\n",
      "tbl       -0.001924\n",
      "svar      -0.003549\n",
      "tms       -0.003748\n",
      "logDY     -0.005897\n",
      "logDP     -0.015612\n",
      "lty       -0.025584\n",
      "ntis      -0.033902\n",
      "logDE     -0.042463\n",
      "dfr       -0.045812\n",
      "logEP     -0.063077\n",
      "b/m       -0.071210\n",
      "dtype: float64\n",
      "\n",
      "Predictors that outperform the benchmark (R^2_OS > 0):\n",
      "lagINFL    0.005288\n",
      "ltr        0.004127\n",
      "dfy        0.001243\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Parameters for out-of-sample forecasting\n",
    "iM = 20 * 4\n",
    "iP = 10 * 4\n",
    "iT = len(dfDATA)\n",
    "\n",
    "# Out-of-sample R^2_OS for each predictor\n",
    "r2_oos = {}\n",
    "pred_detail = {}\n",
    "\n",
    "for p in lPREDICTORS:\n",
    "    preds, benches, reals = [], [], []\n",
    "\n",
    "    # Forecast origins t = iM+iP, ..., iT-1 (because the last row is NaN after shifting)\n",
    "    for t in range(iM + iP, iT - 1):\n",
    "\n",
    "        # Training window: rows [0, t)\n",
    "        dfTRAIN = dfDATA.iloc[:t]\n",
    "\n",
    "        y_train = dfTRAIN[\"r_lead\"]\n",
    "        X_train = sm.add_constant(dfTRAIN[[p]], has_constant='add')\n",
    "\n",
    "        model = sm.OLS(y_train, X_train).fit(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "\n",
    "        # Forecast r_{t+1} using x_t (row t)\n",
    "        X_next = sm.add_constant(dfDATA[[p]].iloc[t:t+1], has_constant='add')\n",
    "        y_pred = float(model.predict(X_next).iloc[0])\n",
    "\n",
    "        # Realized r_{t+1} is r_lead at row t\n",
    "        y_real = float(dfDATA[\"r_lead\"].iloc[t])\n",
    "\n",
    "        # Benchmark: historical mean of realized returns up to t\n",
    "        bench_pred = float(dfDATA[\"r\"].iloc[:t+1].mean())\n",
    "\n",
    "        # Store results \n",
    "        preds.append(y_pred)\n",
    "        benches.append(bench_pred)\n",
    "        reals.append(y_real)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    preds = np.array(preds)\n",
    "    benches = np.array(benches)\n",
    "    reals = np.array(reals)\n",
    "\n",
    "    # Compute R^2_OS by Campbell & Thompson (2008)\n",
    "    ssr_model = np.sum((reals - preds) ** 2)\n",
    "    ssr_bench = np.sum((reals - benches) ** 2)\n",
    "    r2_oos[p] = 1 - ssr_model / ssr_bench\n",
    "\n",
    "    # Store results for this predictor\n",
    "    pred_detail[p] = {\"preds\": preds, \"bench\": benches, \"reals\": reals}\n",
    "\n",
    "# Report: which variables beat the benchmark?\n",
    "r2_series = pd.Series(r2_oos).sort_values(ascending=False)\n",
    "winners = r2_series[r2_series > 0]\n",
    "\n",
    "print(\"Out-of-sample R^2_OS by predictor (expanding window):\")\n",
    "print(r2_series)\n",
    "\n",
    "if len(winners) == 0:\n",
    "    print(\"\\nNo predictor beats the historical-mean benchmark (R^2_OS <= 0).\")\n",
    "else:\n",
    "    print(\"\\nPredictors that outperform the benchmark (R^2_OS > 0):\")\n",
    "    print(winners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11810e",
   "metadata": {},
   "source": [
    "## **Section 3**\n",
    "\n",
    "In this section, we consider the out-of-sample performance of a so-called ”kitchensink” regression in which we include all predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fb0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitchensink (expanding window) R^2_OS: -0.2661835047017449\n"
     ]
    }
   ],
   "source": [
    "# Kitchensink out-of-sample (expanding window) forecast and R^2_OS\n",
    "\n",
    "preds_k, benches_k, reals_k = [], [], []\n",
    "\n",
    "# Expanding-window kitchensink (fit all predictors each period)\n",
    "for t in range(iM + iP, iT - 1):\n",
    "    # training sample uses rows [0, t) -> info up to and including time t\n",
    "    dfTRAIN = dfDATA.iloc[:t]\n",
    "\n",
    "    y_train = dfTRAIN[\"r_lead\"]\n",
    "    X_train = sm.add_constant(dfTRAIN[lPREDICTORS], has_constant='add')\n",
    "    \n",
    "    model_ks = sm.OLS(y_train, X_train).fit(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "\n",
    "    # one-step-ahead forecast of r_{t+1} using x_t (row t)\n",
    "    X_next = sm.add_constant(dfDATA[lPREDICTORS].iloc[t:t+1], has_constant='add')\n",
    "    y_pred = float(model_ks.predict(X_next).iloc[0])\n",
    "\n",
    "    # realized r_{t+1}\n",
    "    y_real = float(dfDATA[\"r_lead\"].iloc[t])\n",
    "\n",
    "    # recursive benchmark mean up to t: \\bar r_{t+1} = (1/t) sum_{j=1}^t r_j\n",
    "    bench_pred = float(dfDATA[\"r\"].iloc[:t+1].mean())\n",
    "\n",
    "    preds_k.append(y_pred)\n",
    "    benches_k.append(bench_pred)\n",
    "    reals_k.append(y_real)\n",
    "\n",
    "preds_k = np.array(preds_k)\n",
    "benches_k = np.array(benches_k)\n",
    "reals_k = np.array(reals_k)\n",
    "\n",
    "# 3) Out-of-sample R^2_OS (Campbell & Thompson)\n",
    "ssr_model_k = np.sum((reals_k - preds_k) ** 2)\n",
    "ssr_bench_k = np.sum((reals_k - benches_k) ** 2)\n",
    "r2_kitchensink = 1 - ssr_model_k / ssr_bench_k\n",
    "\n",
    "print(\"Kitchensink (expanding window) R^2_OS:\", r2_kitchensink)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072fadf",
   "metadata": {},
   "source": [
    "## **Section 4**\n",
    "\n",
    "In the fourth section, we stay in the out-of-sample setting. Individual forecasts may be improved by combining all individual forecasts into a combined forecast. We combined the individual forecasts for period $t + 1$ computed based on equation $(1)$ as follows\n",
    "\n",
    "$$\n",
    "\\hat{r}_{c,t+1} = \\sum_{i=1}^{N} \\omega_{i,t} \\hat{r}_{i,t+1}, \\tag{7}\n",
    "$$\n",
    "\n",
    "where $\\omega_{i,t}$ denotes the ex-ante combination weight for the forecast based on variable $i$ at time $t$. Theoretically, $\\omega_{i,t}$ can vary over $t$, however, they do not need to.\n",
    "\n",
    "First, we consider averaging methods of the individual forecast. For the mean combination forecast, we set the combination weights in equation $(7)$ $\\omega_{i,t} = 1/N$ for each $i = 1, . . . , N$. Next, for the median combination forecast, select the median of $\\{\\hat{r}_{i,t+1}\\}_{i=1}^{N}$. That is, set $\\omega_{j,t} = 1$ for the forecast variable $j \\in \\{1, . . . , N \\}$ associated with the individual forecast being the median forecast $\\hat{r}_{j,t+1}$ of $\\{\\hat{r}_{i,t+1}\\}_{i=1}^{N}$. Otherwise, we set $\\omega_{j,t} = 0$.\n",
    "\n",
    "Using the discount mean square prediction error (DMSPE) method allows the combination weights to depend on the forecast performance of the individual variables over the holdout out-of-sample period (Stock and Watson, 2006). In particular, the combining weights are calculated as\n",
    "\n",
    "$$\n",
    "\\omega_{i,t} = \\Phi^{-1}_{i,t} / \\sum_{j=1}^{N} \\Phi^{-1}_{j,t} \\text{, where    }\n",
    "\\Phi_{i,t} = \\sum_{s=m}^{t-1} \\theta^{t-1-s} (r_{s+1} - \\hat{r}_{i,s+1})^2 \\tag{8}\n",
    "$$\n",
    "\n",
    "with $\\theta > 0$ being a discount factor, $m + 1$ being the first period in the holdout out-of-sample period, and the individual forecast $\\hat{r}_{i,s+1}$ is based on data up to and including period $s$.\n",
    "\n",
    "Therefore, the DMSPE method attaches greater weight to forecast variables whose forecasts yielded lower MSPEs over the holdout out-of-sample period. Furthermore, $\\theta$ controls the degree of discounting. Report results for $\\theta = 0.9$ and $\\theta = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5866126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean comb R^2_OS: -0.005495827047952817\n",
      "Median comb R^2_OS: -0.0020379546498741075\n",
      "DMSPE θ=1 R^2_OS: -0.002467204620882235\n",
      "DMSPE θ=0.9 R^2_OS: 0.0013940223680855013\n"
     ]
    }
   ],
   "source": [
    "# Forecast combinations\n",
    "\n",
    "# Fit individual predictor models once on in-sample + holdout\n",
    "dfTRAIN = dfDATA.iloc[:iM + iP].copy()\n",
    "dfOOS = dfDATA.iloc[iM + iP:iT].copy()\n",
    "\n",
    "y_train = dfTRAIN['r_lead'].to_numpy()\n",
    "y_oos = dfOOS['r_lead'].to_numpy()\n",
    "T_oos = len(y_oos)\n",
    "\n",
    "individual_preds = []  # will store forecasts per predictor\n",
    "\n",
    "for pred in lPREDICTORS:\n",
    "    X_train = sm.add_constant(dfTRAIN[[pred]], has_constant='add')\n",
    "    model_i = sm.OLS(y_train, X_train).fit(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "\n",
    "    X_oos = sm.add_constant(dfOOS[[pred]], has_constant='add')\n",
    "    y_pred = model_i.predict(X_oos).to_numpy()\n",
    "    individual_preds.append(y_pred)\n",
    "\n",
    "# Shape: (N predictors, T_oos)\n",
    "individual_preds = np.vstack(individual_preds)\n",
    "\n",
    "# Combine forecasts\n",
    "# Mean forecast\n",
    "mean_comb = np.mean(individual_preds, axis=0)\n",
    "\n",
    "# Median forecast\n",
    "median_comb = np.median(individual_preds, axis=0)\n",
    "\n",
    "# DMSPE weights\n",
    "def dmspe_weights(individual_preds, y_oos, theta=1.0):\n",
    "    N, T = individual_preds.shape\n",
    "    weights = np.zeros((N, T))\n",
    "    comb_forecast = np.zeros(T)\n",
    "\n",
    "    # start after first OOS obs\n",
    "    for t in range(T):\n",
    "        # compute discounted MSPE up to t\n",
    "        Phi = []\n",
    "        for i in range(N):\n",
    "            errors_sq = (y_oos[:t] - individual_preds[i, :t])**2 if t > 0 else np.array([1e6])\n",
    "            discounts = theta**np.arange(t-1, -1, -1) if t > 0 else np.array([1.0])\n",
    "            Phi_i = np.sum(discounts * errors_sq)\n",
    "            Phi.append(Phi_i)\n",
    "\n",
    "        Phi = np.array(Phi)\n",
    "        invPhi = 1 / Phi\n",
    "        omega = invPhi / invPhi.sum()\n",
    "\n",
    "        weights[:, t] = omega\n",
    "        comb_forecast[t] = (omega @ individual_preds[:, t])\n",
    "\n",
    "    return comb_forecast, weights\n",
    "\n",
    "# DMSPE forecasts\n",
    "dmspe_comb_1, w1 = dmspe_weights(individual_preds, y_oos, theta=1.0)\n",
    "dmspe_comb_09, w09 = dmspe_weights(individual_preds, y_oos, theta=0.9)\n",
    "\n",
    "# Evaluate R^2_OS for each combination\n",
    "def r2_os(y_true, y_pred):\n",
    "    ssr_model = np.sum((y_true - y_pred)**2)\n",
    "    ssr_bench = np.sum((y_true - y_true.mean())**2)  # static mean benchmark\n",
    "    return 1 - ssr_model/ssr_bench\n",
    "\n",
    "print(\"Mean comb R^2_OS:\", r2_os(y_oos, mean_comb))\n",
    "print(\"Median comb R^2_OS:\", r2_os(y_oos, median_comb))\n",
    "print(\"DMSPE θ=1 R^2_OS:\", r2_os(y_oos, dmspe_comb_1))\n",
    "print(\"DMSPE θ=0.9 R^2_OS:\", r2_os(y_oos, dmspe_comb_09))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e57b1",
   "metadata": {},
   "source": [
    "## **References**\n",
    "\n",
    "Campbell, J. Y. and Thompson, S. B. (2008). Predicting excess stock returns out of sample: Can anything beat the historical average? The Review of Financial Studies, 21(4):1509–1531.\n",
    "\n",
    "Rapach, D. E., Ringgenberg, M. C., and Zhou, G. (2016). Short interest and aggregate stock returns. Journal of Financial Economics, 121(1):46–65.\n",
    "\n",
    "Rapach, D. E., Strauss, J. K., and Zhou, G. (2010). Out-of-sample equity premium prediction: Combination forecasts and links to the real economy. The Review of Financial Studies, 23(2):821–862.\n",
    "\n",
    "Stock, J. H. and Watson, M. W. (2006). Forecasting with many predictors. Handbook of Economic Forecasting, 1:515–554.\n",
    "\n",
    "Welch, I. and Goyal, A. (2008). A comprehensive look at the empirical performance of equity premium prediction. The Review of Financial Studies, 21(4):1455–1508."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
